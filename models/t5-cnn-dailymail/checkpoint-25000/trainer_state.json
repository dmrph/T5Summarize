{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 25000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 5.115134239196777,
      "learning_rate": 5.82e-05,
      "loss": 3.5902,
      "step": 100
    },
    {
      "epoch": 0.008,
      "grad_norm": 4.614950180053711,
      "learning_rate": 0.0001182,
      "loss": 2.4495,
      "step": 200
    },
    {
      "epoch": 0.012,
      "grad_norm": 3.514212131500244,
      "learning_rate": 0.00017819999999999997,
      "loss": 2.4436,
      "step": 300
    },
    {
      "epoch": 0.016,
      "grad_norm": 2.9705471992492676,
      "learning_rate": 0.0002382,
      "loss": 2.2546,
      "step": 400
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.317814826965332,
      "learning_rate": 0.0002982,
      "loss": 2.3303,
      "step": 500
    },
    {
      "epoch": 0.024,
      "grad_norm": 4.683045864105225,
      "learning_rate": 0.00029881224489795914,
      "loss": 2.4981,
      "step": 600
    },
    {
      "epoch": 0.028,
      "grad_norm": 3.488828659057617,
      "learning_rate": 0.00029758775510204077,
      "loss": 2.3222,
      "step": 700
    },
    {
      "epoch": 0.032,
      "grad_norm": 3.216190814971924,
      "learning_rate": 0.0002963755102040816,
      "loss": 2.292,
      "step": 800
    },
    {
      "epoch": 0.036,
      "grad_norm": 5.115143775939941,
      "learning_rate": 0.00029515102040816323,
      "loss": 2.3429,
      "step": 900
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.6023452281951904,
      "learning_rate": 0.00029392653061224486,
      "loss": 2.353,
      "step": 1000
    },
    {
      "epoch": 0.044,
      "grad_norm": 3.4269886016845703,
      "learning_rate": 0.0002927020408163265,
      "loss": 2.3753,
      "step": 1100
    },
    {
      "epoch": 0.048,
      "grad_norm": 3.2547860145568848,
      "learning_rate": 0.0002914775510204081,
      "loss": 2.4175,
      "step": 1200
    },
    {
      "epoch": 0.052,
      "grad_norm": 2.585005044937134,
      "learning_rate": 0.0002902530612244898,
      "loss": 2.3011,
      "step": 1300
    },
    {
      "epoch": 0.056,
      "grad_norm": 3.3330390453338623,
      "learning_rate": 0.0002890285714285714,
      "loss": 2.3664,
      "step": 1400
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.0156612396240234,
      "learning_rate": 0.00028780408163265307,
      "loss": 2.3579,
      "step": 1500
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.9585702419281006,
      "learning_rate": 0.00028657959183673464,
      "loss": 2.3488,
      "step": 1600
    },
    {
      "epoch": 0.068,
      "grad_norm": 4.629729270935059,
      "learning_rate": 0.0002853551020408163,
      "loss": 2.4081,
      "step": 1700
    },
    {
      "epoch": 0.072,
      "grad_norm": 3.051316022872925,
      "learning_rate": 0.00028413061224489796,
      "loss": 2.3408,
      "step": 1800
    },
    {
      "epoch": 0.076,
      "grad_norm": 3.2228920459747314,
      "learning_rate": 0.00028290612244897954,
      "loss": 2.3752,
      "step": 1900
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.6375794410705566,
      "learning_rate": 0.0002816816326530612,
      "loss": 2.4253,
      "step": 2000
    },
    {
      "epoch": 0.084,
      "grad_norm": 3.5673022270202637,
      "learning_rate": 0.00028045714285714285,
      "loss": 2.393,
      "step": 2100
    },
    {
      "epoch": 0.088,
      "grad_norm": 2.383824586868286,
      "learning_rate": 0.0002792326530612245,
      "loss": 2.3026,
      "step": 2200
    },
    {
      "epoch": 0.092,
      "grad_norm": 3.765009641647339,
      "learning_rate": 0.0002780081632653061,
      "loss": 2.2884,
      "step": 2300
    },
    {
      "epoch": 0.096,
      "grad_norm": 2.417527437210083,
      "learning_rate": 0.00027678367346938774,
      "loss": 2.4189,
      "step": 2400
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.3388564586639404,
      "learning_rate": 0.0002755591836734694,
      "loss": 2.4144,
      "step": 2500
    },
    {
      "epoch": 0.104,
      "grad_norm": 3.487091541290283,
      "learning_rate": 0.000274334693877551,
      "loss": 2.3098,
      "step": 2600
    },
    {
      "epoch": 0.108,
      "grad_norm": 3.192767381668091,
      "learning_rate": 0.00027311020408163263,
      "loss": 2.3363,
      "step": 2700
    },
    {
      "epoch": 0.112,
      "grad_norm": 3.410006523132324,
      "learning_rate": 0.00027188571428571427,
      "loss": 2.3655,
      "step": 2800
    },
    {
      "epoch": 0.116,
      "grad_norm": 3.198183059692383,
      "learning_rate": 0.0002706612244897959,
      "loss": 2.3584,
      "step": 2900
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.207165479660034,
      "learning_rate": 0.0002694367346938775,
      "loss": 2.4802,
      "step": 3000
    },
    {
      "epoch": 0.124,
      "grad_norm": 3.6007959842681885,
      "learning_rate": 0.00026821224489795916,
      "loss": 2.2987,
      "step": 3100
    },
    {
      "epoch": 0.128,
      "grad_norm": 3.650240421295166,
      "learning_rate": 0.0002669877551020408,
      "loss": 2.3459,
      "step": 3200
    },
    {
      "epoch": 0.132,
      "grad_norm": 3.3307106494903564,
      "learning_rate": 0.0002657632653061224,
      "loss": 2.3051,
      "step": 3300
    },
    {
      "epoch": 0.136,
      "grad_norm": 3.037367582321167,
      "learning_rate": 0.00026455102040816325,
      "loss": 2.2539,
      "step": 3400
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.2757949829101562,
      "learning_rate": 0.0002633265306122449,
      "loss": 2.3867,
      "step": 3500
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.088656425476074,
      "learning_rate": 0.0002621020408163265,
      "loss": 2.347,
      "step": 3600
    },
    {
      "epoch": 0.148,
      "grad_norm": 2.5839011669158936,
      "learning_rate": 0.00026087755102040814,
      "loss": 2.2838,
      "step": 3700
    },
    {
      "epoch": 0.152,
      "grad_norm": 2.8593549728393555,
      "learning_rate": 0.00025965306122448977,
      "loss": 2.3899,
      "step": 3800
    },
    {
      "epoch": 0.156,
      "grad_norm": 2.500790596008301,
      "learning_rate": 0.0002584285714285714,
      "loss": 2.3902,
      "step": 3900
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.3521947860717773,
      "learning_rate": 0.00025720408163265303,
      "loss": 2.3002,
      "step": 4000
    },
    {
      "epoch": 0.164,
      "grad_norm": 2.7113282680511475,
      "learning_rate": 0.00025597959183673466,
      "loss": 2.3949,
      "step": 4100
    },
    {
      "epoch": 0.168,
      "grad_norm": 2.7622172832489014,
      "learning_rate": 0.0002547551020408163,
      "loss": 2.3355,
      "step": 4200
    },
    {
      "epoch": 0.172,
      "grad_norm": 3.217268466949463,
      "learning_rate": 0.0002535306122448979,
      "loss": 2.2233,
      "step": 4300
    },
    {
      "epoch": 0.176,
      "grad_norm": 2.55879807472229,
      "learning_rate": 0.00025230612244897955,
      "loss": 2.3422,
      "step": 4400
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7139816284179688,
      "learning_rate": 0.00025108163265306124,
      "loss": 2.3333,
      "step": 4500
    },
    {
      "epoch": 0.184,
      "grad_norm": 2.799598455429077,
      "learning_rate": 0.0002498571428571428,
      "loss": 2.2746,
      "step": 4600
    },
    {
      "epoch": 0.188,
      "grad_norm": 2.8462045192718506,
      "learning_rate": 0.00024863265306122444,
      "loss": 2.2537,
      "step": 4700
    },
    {
      "epoch": 0.192,
      "grad_norm": 4.02197265625,
      "learning_rate": 0.00024740816326530613,
      "loss": 2.3304,
      "step": 4800
    },
    {
      "epoch": 0.196,
      "grad_norm": 2.7865376472473145,
      "learning_rate": 0.0002461836734693877,
      "loss": 2.2868,
      "step": 4900
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.610682964324951,
      "learning_rate": 0.0002449591836734694,
      "loss": 2.3822,
      "step": 5000
    },
    {
      "epoch": 0.204,
      "grad_norm": 6.462612152099609,
      "learning_rate": 0.000243734693877551,
      "loss": 2.2509,
      "step": 5100
    },
    {
      "epoch": 0.208,
      "grad_norm": 3.5984585285186768,
      "learning_rate": 0.00024251020408163265,
      "loss": 2.3271,
      "step": 5200
    },
    {
      "epoch": 0.212,
      "grad_norm": 3.138456344604492,
      "learning_rate": 0.00024128571428571425,
      "loss": 2.343,
      "step": 5300
    },
    {
      "epoch": 0.216,
      "grad_norm": 3.109773635864258,
      "learning_rate": 0.0002400612244897959,
      "loss": 2.3323,
      "step": 5400
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8837099075317383,
      "learning_rate": 0.00023883673469387754,
      "loss": 2.3516,
      "step": 5500
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.251843214035034,
      "learning_rate": 0.00023761224489795914,
      "loss": 2.3015,
      "step": 5600
    },
    {
      "epoch": 0.228,
      "grad_norm": 2.9656028747558594,
      "learning_rate": 0.0002363877551020408,
      "loss": 2.2036,
      "step": 5700
    },
    {
      "epoch": 0.232,
      "grad_norm": 4.685922145843506,
      "learning_rate": 0.0002351632653061224,
      "loss": 2.3883,
      "step": 5800
    },
    {
      "epoch": 0.236,
      "grad_norm": 3.2078120708465576,
      "learning_rate": 0.00023393877551020406,
      "loss": 2.3591,
      "step": 5900
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.8258397579193115,
      "learning_rate": 0.0002327142857142857,
      "loss": 2.2984,
      "step": 6000
    },
    {
      "epoch": 0.244,
      "grad_norm": 2.805661678314209,
      "learning_rate": 0.00023148979591836732,
      "loss": 2.3362,
      "step": 6100
    },
    {
      "epoch": 0.248,
      "grad_norm": 2.9041953086853027,
      "learning_rate": 0.00023026530612244896,
      "loss": 2.3286,
      "step": 6200
    },
    {
      "epoch": 0.252,
      "grad_norm": 2.9798583984375,
      "learning_rate": 0.0002290408163265306,
      "loss": 2.3773,
      "step": 6300
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.9929144382476807,
      "learning_rate": 0.00022781632653061222,
      "loss": 2.4253,
      "step": 6400
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.955840587615967,
      "learning_rate": 0.00022659183673469385,
      "loss": 2.2498,
      "step": 6500
    },
    {
      "epoch": 0.264,
      "grad_norm": 3.3571794033050537,
      "learning_rate": 0.0002253673469387755,
      "loss": 2.2405,
      "step": 6600
    },
    {
      "epoch": 0.268,
      "grad_norm": 2.211303949356079,
      "learning_rate": 0.0002241428571428571,
      "loss": 2.3208,
      "step": 6700
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.943838119506836,
      "learning_rate": 0.00022291836734693877,
      "loss": 2.321,
      "step": 6800
    },
    {
      "epoch": 0.276,
      "grad_norm": 3.2400360107421875,
      "learning_rate": 0.00022169387755102037,
      "loss": 2.3439,
      "step": 6900
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.995591402053833,
      "learning_rate": 0.00022046938775510203,
      "loss": 2.3034,
      "step": 7000
    },
    {
      "epoch": 0.284,
      "grad_norm": 3.2658071517944336,
      "learning_rate": 0.00021924489795918366,
      "loss": 2.3661,
      "step": 7100
    },
    {
      "epoch": 0.288,
      "grad_norm": 3.4590322971343994,
      "learning_rate": 0.00021802040816326532,
      "loss": 2.3409,
      "step": 7200
    },
    {
      "epoch": 0.292,
      "grad_norm": 3.2705368995666504,
      "learning_rate": 0.00021679591836734692,
      "loss": 2.2897,
      "step": 7300
    },
    {
      "epoch": 0.296,
      "grad_norm": 2.7530367374420166,
      "learning_rate": 0.00021557142857142855,
      "loss": 2.3091,
      "step": 7400
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.5193984508514404,
      "learning_rate": 0.00021435918367346938,
      "loss": 2.4323,
      "step": 7500
    },
    {
      "epoch": 0.304,
      "grad_norm": 4.01898193359375,
      "learning_rate": 0.000213134693877551,
      "loss": 2.3627,
      "step": 7600
    },
    {
      "epoch": 0.308,
      "grad_norm": 2.6338279247283936,
      "learning_rate": 0.00021191020408163264,
      "loss": 2.2939,
      "step": 7700
    },
    {
      "epoch": 0.312,
      "grad_norm": 2.7106895446777344,
      "learning_rate": 0.00021068571428571427,
      "loss": 2.4086,
      "step": 7800
    },
    {
      "epoch": 0.316,
      "grad_norm": 2.194382667541504,
      "learning_rate": 0.0002094612244897959,
      "loss": 2.302,
      "step": 7900
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.713409900665283,
      "learning_rate": 0.00020823673469387753,
      "loss": 2.3095,
      "step": 8000
    },
    {
      "epoch": 0.324,
      "grad_norm": 3.5526983737945557,
      "learning_rate": 0.00020701224489795916,
      "loss": 2.258,
      "step": 8100
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.642805814743042,
      "learning_rate": 0.00020578775510204082,
      "loss": 2.2857,
      "step": 8200
    },
    {
      "epoch": 0.332,
      "grad_norm": 3.659578800201416,
      "learning_rate": 0.00020456326530612242,
      "loss": 2.3081,
      "step": 8300
    },
    {
      "epoch": 0.336,
      "grad_norm": 4.967989921569824,
      "learning_rate": 0.00020333877551020408,
      "loss": 2.2667,
      "step": 8400
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.666802406311035,
      "learning_rate": 0.00020211428571428568,
      "loss": 2.3344,
      "step": 8500
    },
    {
      "epoch": 0.344,
      "grad_norm": 4.102543354034424,
      "learning_rate": 0.0002008897959183673,
      "loss": 2.2541,
      "step": 8600
    },
    {
      "epoch": 0.348,
      "grad_norm": 2.859168767929077,
      "learning_rate": 0.00019966530612244897,
      "loss": 2.3219,
      "step": 8700
    },
    {
      "epoch": 0.352,
      "grad_norm": 5.053003311157227,
      "learning_rate": 0.00019844081632653057,
      "loss": 2.2399,
      "step": 8800
    },
    {
      "epoch": 0.356,
      "grad_norm": 3.1230249404907227,
      "learning_rate": 0.00019721632653061223,
      "loss": 2.284,
      "step": 8900
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6963064670562744,
      "learning_rate": 0.00019599183673469386,
      "loss": 2.4312,
      "step": 9000
    },
    {
      "epoch": 0.364,
      "grad_norm": 2.747730016708374,
      "learning_rate": 0.0001947673469387755,
      "loss": 2.2804,
      "step": 9100
    },
    {
      "epoch": 0.368,
      "grad_norm": 3.884676933288574,
      "learning_rate": 0.00019354285714285712,
      "loss": 2.3404,
      "step": 9200
    },
    {
      "epoch": 0.372,
      "grad_norm": 5.001678943634033,
      "learning_rate": 0.00019231836734693878,
      "loss": 2.2654,
      "step": 9300
    },
    {
      "epoch": 0.376,
      "grad_norm": 3.1480181217193604,
      "learning_rate": 0.00019109387755102038,
      "loss": 2.3787,
      "step": 9400
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.1993815898895264,
      "learning_rate": 0.00018986938775510201,
      "loss": 2.2107,
      "step": 9500
    },
    {
      "epoch": 0.384,
      "grad_norm": 3.1547493934631348,
      "learning_rate": 0.00018864489795918367,
      "loss": 2.2768,
      "step": 9600
    },
    {
      "epoch": 0.388,
      "grad_norm": 4.397828578948975,
      "learning_rate": 0.00018742040816326528,
      "loss": 2.2706,
      "step": 9700
    },
    {
      "epoch": 0.392,
      "grad_norm": 2.876007318496704,
      "learning_rate": 0.00018619591836734693,
      "loss": 2.2642,
      "step": 9800
    },
    {
      "epoch": 0.396,
      "grad_norm": 4.184474945068359,
      "learning_rate": 0.00018497142857142854,
      "loss": 2.2462,
      "step": 9900
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.7426726818084717,
      "learning_rate": 0.0001837469387755102,
      "loss": 2.257,
      "step": 10000
    },
    {
      "epoch": 0.404,
      "grad_norm": 2.6918630599975586,
      "learning_rate": 0.00018252244897959183,
      "loss": 2.259,
      "step": 10100
    },
    {
      "epoch": 0.408,
      "grad_norm": 3.801284074783325,
      "learning_rate": 0.00018129795918367346,
      "loss": 2.3242,
      "step": 10200
    },
    {
      "epoch": 0.412,
      "grad_norm": 3.70735239982605,
      "learning_rate": 0.00018007346938775509,
      "loss": 2.3547,
      "step": 10300
    },
    {
      "epoch": 0.416,
      "grad_norm": 2.8746559619903564,
      "learning_rate": 0.00017884897959183672,
      "loss": 2.2511,
      "step": 10400
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.5263848304748535,
      "learning_rate": 0.00017762448979591835,
      "loss": 2.2686,
      "step": 10500
    },
    {
      "epoch": 0.424,
      "grad_norm": 3.100192070007324,
      "learning_rate": 0.00017639999999999998,
      "loss": 2.2976,
      "step": 10600
    },
    {
      "epoch": 0.428,
      "grad_norm": 3.8606066703796387,
      "learning_rate": 0.00017517551020408164,
      "loss": 2.2809,
      "step": 10700
    },
    {
      "epoch": 0.432,
      "grad_norm": 2.527825117111206,
      "learning_rate": 0.00017395102040816324,
      "loss": 2.2983,
      "step": 10800
    },
    {
      "epoch": 0.436,
      "grad_norm": 2.899721145629883,
      "learning_rate": 0.0001727265306122449,
      "loss": 2.256,
      "step": 10900
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.646122455596924,
      "learning_rate": 0.0001715020408163265,
      "loss": 2.3258,
      "step": 11000
    },
    {
      "epoch": 0.444,
      "grad_norm": 3.477067232131958,
      "learning_rate": 0.00017027755102040816,
      "loss": 2.2415,
      "step": 11100
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.5089008808135986,
      "learning_rate": 0.00016906530612244899,
      "loss": 2.2466,
      "step": 11200
    },
    {
      "epoch": 0.452,
      "grad_norm": 2.0211501121520996,
      "learning_rate": 0.0001678408163265306,
      "loss": 2.3355,
      "step": 11300
    },
    {
      "epoch": 0.456,
      "grad_norm": 2.8965933322906494,
      "learning_rate": 0.00016661632653061225,
      "loss": 2.2559,
      "step": 11400
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.904721260070801,
      "learning_rate": 0.00016539183673469385,
      "loss": 2.2018,
      "step": 11500
    },
    {
      "epoch": 0.464,
      "grad_norm": 3.945927858352661,
      "learning_rate": 0.00016416734693877548,
      "loss": 2.323,
      "step": 11600
    },
    {
      "epoch": 0.468,
      "grad_norm": 2.3843162059783936,
      "learning_rate": 0.00016294285714285714,
      "loss": 2.2934,
      "step": 11700
    },
    {
      "epoch": 0.472,
      "grad_norm": 3.448060989379883,
      "learning_rate": 0.00016171836734693874,
      "loss": 2.2109,
      "step": 11800
    },
    {
      "epoch": 0.476,
      "grad_norm": 2.302905559539795,
      "learning_rate": 0.0001604938775510204,
      "loss": 2.188,
      "step": 11900
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.6396267414093018,
      "learning_rate": 0.00015926938775510203,
      "loss": 2.2437,
      "step": 12000
    },
    {
      "epoch": 0.484,
      "grad_norm": 2.713901996612549,
      "learning_rate": 0.00015804489795918366,
      "loss": 2.2448,
      "step": 12100
    },
    {
      "epoch": 0.488,
      "grad_norm": 3.3195362091064453,
      "learning_rate": 0.0001568204081632653,
      "loss": 2.1756,
      "step": 12200
    },
    {
      "epoch": 0.492,
      "grad_norm": 3.2508223056793213,
      "learning_rate": 0.00015559591836734695,
      "loss": 2.335,
      "step": 12300
    },
    {
      "epoch": 0.496,
      "grad_norm": 2.2378382682800293,
      "learning_rate": 0.00015437142857142855,
      "loss": 2.2489,
      "step": 12400
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.6281139850616455,
      "learning_rate": 0.00015314693877551018,
      "loss": 2.3058,
      "step": 12500
    },
    {
      "epoch": 0.504,
      "grad_norm": 2.892181873321533,
      "learning_rate": 0.0001519224489795918,
      "loss": 2.2371,
      "step": 12600
    },
    {
      "epoch": 0.508,
      "grad_norm": 3.950317859649658,
      "learning_rate": 0.00015069795918367344,
      "loss": 2.2766,
      "step": 12700
    },
    {
      "epoch": 0.512,
      "grad_norm": 2.506160259246826,
      "learning_rate": 0.0001494734693877551,
      "loss": 2.2828,
      "step": 12800
    },
    {
      "epoch": 0.516,
      "grad_norm": 4.034144401550293,
      "learning_rate": 0.0001482489795918367,
      "loss": 2.2243,
      "step": 12900
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.0961754322052,
      "learning_rate": 0.00014702448979591834,
      "loss": 2.2613,
      "step": 13000
    },
    {
      "epoch": 0.524,
      "grad_norm": 2.4203546047210693,
      "learning_rate": 0.0001458,
      "loss": 2.2454,
      "step": 13100
    },
    {
      "epoch": 0.528,
      "grad_norm": 2.7334773540496826,
      "learning_rate": 0.00014457551020408162,
      "loss": 2.2888,
      "step": 13200
    },
    {
      "epoch": 0.532,
      "grad_norm": 2.571629047393799,
      "learning_rate": 0.00014336326530612245,
      "loss": 2.1634,
      "step": 13300
    },
    {
      "epoch": 0.536,
      "grad_norm": 2.6862618923187256,
      "learning_rate": 0.00014213877551020405,
      "loss": 2.2897,
      "step": 13400
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5413568019866943,
      "learning_rate": 0.00014091428571428569,
      "loss": 2.1878,
      "step": 13500
    },
    {
      "epoch": 0.544,
      "grad_norm": 2.5223724842071533,
      "learning_rate": 0.00013968979591836734,
      "loss": 2.1703,
      "step": 13600
    },
    {
      "epoch": 0.548,
      "grad_norm": 3.4135282039642334,
      "learning_rate": 0.00013846530612244897,
      "loss": 2.1858,
      "step": 13700
    },
    {
      "epoch": 0.552,
      "grad_norm": 3.151003360748291,
      "learning_rate": 0.0001372408163265306,
      "loss": 2.192,
      "step": 13800
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.833508014678955,
      "learning_rate": 0.00013601632653061223,
      "loss": 2.2141,
      "step": 13900
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.409362316131592,
      "learning_rate": 0.00013479183673469387,
      "loss": 2.1645,
      "step": 14000
    },
    {
      "epoch": 0.564,
      "grad_norm": 2.8194398880004883,
      "learning_rate": 0.0001335673469387755,
      "loss": 2.2311,
      "step": 14100
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.8065614700317383,
      "learning_rate": 0.00013234285714285713,
      "loss": 2.2574,
      "step": 14200
    },
    {
      "epoch": 0.572,
      "grad_norm": 3.409212350845337,
      "learning_rate": 0.00013111836734693876,
      "loss": 2.14,
      "step": 14300
    },
    {
      "epoch": 0.576,
      "grad_norm": 2.6359195709228516,
      "learning_rate": 0.0001298938775510204,
      "loss": 2.2958,
      "step": 14400
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.837146759033203,
      "learning_rate": 0.00012866938775510202,
      "loss": 2.3495,
      "step": 14500
    },
    {
      "epoch": 0.584,
      "grad_norm": 2.297260284423828,
      "learning_rate": 0.00012744489795918365,
      "loss": 2.3566,
      "step": 14600
    },
    {
      "epoch": 0.588,
      "grad_norm": 3.9945051670074463,
      "learning_rate": 0.0001262204081632653,
      "loss": 2.249,
      "step": 14700
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.834068775177002,
      "learning_rate": 0.00012499591836734694,
      "loss": 2.2297,
      "step": 14800
    },
    {
      "epoch": 0.596,
      "grad_norm": 2.8293514251708984,
      "learning_rate": 0.00012377142857142857,
      "loss": 2.218,
      "step": 14900
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.569075584411621,
      "learning_rate": 0.0001225469387755102,
      "loss": 2.3052,
      "step": 15000
    },
    {
      "epoch": 0.604,
      "grad_norm": 3.1383254528045654,
      "learning_rate": 0.00012132244897959181,
      "loss": 2.2111,
      "step": 15100
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.2597427368164062,
      "learning_rate": 0.00012009795918367346,
      "loss": 2.2218,
      "step": 15200
    },
    {
      "epoch": 0.612,
      "grad_norm": 3.6377251148223877,
      "learning_rate": 0.00011887346938775509,
      "loss": 2.2542,
      "step": 15300
    },
    {
      "epoch": 0.616,
      "grad_norm": 2.210156202316284,
      "learning_rate": 0.00011764897959183672,
      "loss": 2.2419,
      "step": 15400
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.3223233222961426,
      "learning_rate": 0.00011642448979591836,
      "loss": 2.1867,
      "step": 15500
    },
    {
      "epoch": 0.624,
      "grad_norm": 3.9224472045898438,
      "learning_rate": 0.0001152,
      "loss": 2.2383,
      "step": 15600
    },
    {
      "epoch": 0.628,
      "grad_norm": 3.70827054977417,
      "learning_rate": 0.00011397551020408163,
      "loss": 2.2626,
      "step": 15700
    },
    {
      "epoch": 0.632,
      "grad_norm": 2.9978067874908447,
      "learning_rate": 0.00011275102040816326,
      "loss": 2.2491,
      "step": 15800
    },
    {
      "epoch": 0.636,
      "grad_norm": 2.61733078956604,
      "learning_rate": 0.0001115265306122449,
      "loss": 2.284,
      "step": 15900
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.31567645072937,
      "learning_rate": 0.00011030204081632652,
      "loss": 2.2114,
      "step": 16000
    },
    {
      "epoch": 0.644,
      "grad_norm": 2.009934425354004,
      "learning_rate": 0.00010907755102040815,
      "loss": 2.1259,
      "step": 16100
    },
    {
      "epoch": 0.648,
      "grad_norm": 3.499882936477661,
      "learning_rate": 0.00010785306122448978,
      "loss": 2.2245,
      "step": 16200
    },
    {
      "epoch": 0.652,
      "grad_norm": 2.6628177165985107,
      "learning_rate": 0.0001066408163265306,
      "loss": 2.3094,
      "step": 16300
    },
    {
      "epoch": 0.656,
      "grad_norm": 2.6004061698913574,
      "learning_rate": 0.00010541632653061225,
      "loss": 2.3383,
      "step": 16400
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.7385966777801514,
      "learning_rate": 0.00010419183673469387,
      "loss": 2.267,
      "step": 16500
    },
    {
      "epoch": 0.664,
      "grad_norm": 2.9615938663482666,
      "learning_rate": 0.0001029673469387755,
      "loss": 2.2304,
      "step": 16600
    },
    {
      "epoch": 0.668,
      "grad_norm": 2.8612310886383057,
      "learning_rate": 0.00010174285714285713,
      "loss": 2.293,
      "step": 16700
    },
    {
      "epoch": 0.672,
      "grad_norm": 3.4182043075561523,
      "learning_rate": 0.00010051836734693877,
      "loss": 2.3783,
      "step": 16800
    },
    {
      "epoch": 0.676,
      "grad_norm": 3.743886709213257,
      "learning_rate": 9.92938775510204e-05,
      "loss": 2.26,
      "step": 16900
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6064672470092773,
      "learning_rate": 9.806938775510203e-05,
      "loss": 2.3015,
      "step": 17000
    },
    {
      "epoch": 0.684,
      "grad_norm": 2.749431610107422,
      "learning_rate": 9.684489795918366e-05,
      "loss": 2.2217,
      "step": 17100
    },
    {
      "epoch": 0.688,
      "grad_norm": 3.052669048309326,
      "learning_rate": 9.562040816326531e-05,
      "loss": 2.1812,
      "step": 17200
    },
    {
      "epoch": 0.692,
      "grad_norm": 2.151810884475708,
      "learning_rate": 9.439591836734692e-05,
      "loss": 2.21,
      "step": 17300
    },
    {
      "epoch": 0.696,
      "grad_norm": 3.209214210510254,
      "learning_rate": 9.317142857142856e-05,
      "loss": 2.2948,
      "step": 17400
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.665631055831909,
      "learning_rate": 9.194693877551019e-05,
      "loss": 2.1538,
      "step": 17500
    },
    {
      "epoch": 0.704,
      "grad_norm": 4.255517959594727,
      "learning_rate": 9.072244897959183e-05,
      "loss": 2.3009,
      "step": 17600
    },
    {
      "epoch": 0.708,
      "grad_norm": 2.512322425842285,
      "learning_rate": 8.949795918367346e-05,
      "loss": 2.1309,
      "step": 17700
    },
    {
      "epoch": 0.712,
      "grad_norm": 3.0136570930480957,
      "learning_rate": 8.827346938775509e-05,
      "loss": 2.2586,
      "step": 17800
    },
    {
      "epoch": 0.716,
      "grad_norm": 2.7356934547424316,
      "learning_rate": 8.704897959183674e-05,
      "loss": 2.2378,
      "step": 17900
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.5955073833465576,
      "learning_rate": 8.582448979591837e-05,
      "loss": 2.1862,
      "step": 18000
    },
    {
      "epoch": 0.724,
      "grad_norm": 3.1982245445251465,
      "learning_rate": 8.459999999999998e-05,
      "loss": 2.254,
      "step": 18100
    },
    {
      "epoch": 0.728,
      "grad_norm": 4.646820545196533,
      "learning_rate": 8.337551020408161e-05,
      "loss": 2.2613,
      "step": 18200
    },
    {
      "epoch": 0.732,
      "grad_norm": 2.3440773487091064,
      "learning_rate": 8.215102040816326e-05,
      "loss": 2.2322,
      "step": 18300
    },
    {
      "epoch": 0.736,
      "grad_norm": 2.046358108520508,
      "learning_rate": 8.092653061224489e-05,
      "loss": 2.1698,
      "step": 18400
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.57126522064209,
      "learning_rate": 7.970204081632652e-05,
      "loss": 2.2215,
      "step": 18500
    },
    {
      "epoch": 0.744,
      "grad_norm": 2.404693126678467,
      "learning_rate": 7.847755102040816e-05,
      "loss": 2.1025,
      "step": 18600
    },
    {
      "epoch": 0.748,
      "grad_norm": 2.974307060241699,
      "learning_rate": 7.725306122448979e-05,
      "loss": 2.0355,
      "step": 18700
    },
    {
      "epoch": 0.752,
      "grad_norm": 3.5402286052703857,
      "learning_rate": 7.602857142857142e-05,
      "loss": 2.2944,
      "step": 18800
    },
    {
      "epoch": 0.756,
      "grad_norm": 3.3189008235931396,
      "learning_rate": 7.480408163265305e-05,
      "loss": 2.364,
      "step": 18900
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.535698890686035,
      "learning_rate": 7.357959183673468e-05,
      "loss": 2.1622,
      "step": 19000
    },
    {
      "epoch": 0.764,
      "grad_norm": 2.291212320327759,
      "learning_rate": 7.235510204081633e-05,
      "loss": 2.1945,
      "step": 19100
    },
    {
      "epoch": 0.768,
      "grad_norm": 3.3112785816192627,
      "learning_rate": 7.113061224489795e-05,
      "loss": 2.2852,
      "step": 19200
    },
    {
      "epoch": 0.772,
      "grad_norm": 2.837758779525757,
      "learning_rate": 6.990612244897959e-05,
      "loss": 2.2577,
      "step": 19300
    },
    {
      "epoch": 0.776,
      "grad_norm": 2.108250856399536,
      "learning_rate": 6.868163265306122e-05,
      "loss": 2.266,
      "step": 19400
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.992760181427002,
      "learning_rate": 6.745714285714285e-05,
      "loss": 2.1609,
      "step": 19500
    },
    {
      "epoch": 0.784,
      "grad_norm": 3.167973756790161,
      "learning_rate": 6.623265306122448e-05,
      "loss": 2.1495,
      "step": 19600
    },
    {
      "epoch": 0.788,
      "grad_norm": 2.9959330558776855,
      "learning_rate": 6.500816326530611e-05,
      "loss": 2.1778,
      "step": 19700
    },
    {
      "epoch": 0.792,
      "grad_norm": 4.171597957611084,
      "learning_rate": 6.378367346938776e-05,
      "loss": 2.2059,
      "step": 19800
    },
    {
      "epoch": 0.796,
      "grad_norm": 2.959693431854248,
      "learning_rate": 6.255918367346939e-05,
      "loss": 2.2794,
      "step": 19900
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.579033851623535,
      "learning_rate": 6.133469387755102e-05,
      "loss": 2.1701,
      "step": 20000
    },
    {
      "epoch": 0.804,
      "grad_norm": 2.2293248176574707,
      "learning_rate": 6.011020408163265e-05,
      "loss": 2.3056,
      "step": 20100
    },
    {
      "epoch": 0.808,
      "grad_norm": 3.745149612426758,
      "learning_rate": 5.888571428571428e-05,
      "loss": 2.2846,
      "step": 20200
    },
    {
      "epoch": 0.812,
      "grad_norm": 2.932746171951294,
      "learning_rate": 5.76734693877551e-05,
      "loss": 2.1633,
      "step": 20300
    },
    {
      "epoch": 0.816,
      "grad_norm": 3.23941969871521,
      "learning_rate": 5.644897959183673e-05,
      "loss": 2.2466,
      "step": 20400
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.547625780105591,
      "learning_rate": 5.522448979591836e-05,
      "loss": 2.2161,
      "step": 20500
    },
    {
      "epoch": 0.824,
      "grad_norm": 4.199340343475342,
      "learning_rate": 5.399999999999999e-05,
      "loss": 2.11,
      "step": 20600
    },
    {
      "epoch": 0.828,
      "grad_norm": 2.9422690868377686,
      "learning_rate": 5.277551020408163e-05,
      "loss": 2.3017,
      "step": 20700
    },
    {
      "epoch": 0.832,
      "grad_norm": 2.345553159713745,
      "learning_rate": 5.1551020408163266e-05,
      "loss": 2.2422,
      "step": 20800
    },
    {
      "epoch": 0.836,
      "grad_norm": 2.4821419715881348,
      "learning_rate": 5.0326530612244896e-05,
      "loss": 2.191,
      "step": 20900
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.1452691555023193,
      "learning_rate": 4.910204081632653e-05,
      "loss": 2.198,
      "step": 21000
    },
    {
      "epoch": 0.844,
      "grad_norm": 2.585651397705078,
      "learning_rate": 4.787755102040816e-05,
      "loss": 2.2586,
      "step": 21100
    },
    {
      "epoch": 0.848,
      "grad_norm": 2.5972249507904053,
      "learning_rate": 4.6653061224489795e-05,
      "loss": 2.2456,
      "step": 21200
    },
    {
      "epoch": 0.852,
      "grad_norm": 2.4490694999694824,
      "learning_rate": 4.5428571428571425e-05,
      "loss": 2.1207,
      "step": 21300
    },
    {
      "epoch": 0.856,
      "grad_norm": 3.0902066230773926,
      "learning_rate": 4.4204081632653056e-05,
      "loss": 2.2091,
      "step": 21400
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1857171058654785,
      "learning_rate": 4.2979591836734686e-05,
      "loss": 2.1272,
      "step": 21500
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.976779580116272,
      "learning_rate": 4.1755102040816324e-05,
      "loss": 2.1418,
      "step": 21600
    },
    {
      "epoch": 0.868,
      "grad_norm": 2.521979570388794,
      "learning_rate": 4.053061224489796e-05,
      "loss": 2.2443,
      "step": 21700
    },
    {
      "epoch": 0.872,
      "grad_norm": 3.306942939758301,
      "learning_rate": 3.9306122448979585e-05,
      "loss": 2.1396,
      "step": 21800
    },
    {
      "epoch": 0.876,
      "grad_norm": 2.7809393405914307,
      "learning_rate": 3.80938775510204e-05,
      "loss": 2.196,
      "step": 21900
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.87796950340271,
      "learning_rate": 3.6869387755102036e-05,
      "loss": 2.1297,
      "step": 22000
    },
    {
      "epoch": 0.884,
      "grad_norm": 7.146238803863525,
      "learning_rate": 3.5644897959183674e-05,
      "loss": 2.2152,
      "step": 22100
    },
    {
      "epoch": 0.888,
      "grad_norm": 3.0579349994659424,
      "learning_rate": 3.4420408163265304e-05,
      "loss": 2.1599,
      "step": 22200
    },
    {
      "epoch": 0.892,
      "grad_norm": 3.7070064544677734,
      "learning_rate": 3.3195918367346935e-05,
      "loss": 2.1605,
      "step": 22300
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.539722442626953,
      "learning_rate": 3.1971428571428565e-05,
      "loss": 2.2522,
      "step": 22400
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.08577299118042,
      "learning_rate": 3.07469387755102e-05,
      "loss": 2.3065,
      "step": 22500
    },
    {
      "epoch": 0.904,
      "grad_norm": 2.3913514614105225,
      "learning_rate": 2.9522448979591833e-05,
      "loss": 2.2482,
      "step": 22600
    },
    {
      "epoch": 0.908,
      "grad_norm": 3.772958517074585,
      "learning_rate": 2.8297959183673467e-05,
      "loss": 2.2219,
      "step": 22700
    },
    {
      "epoch": 0.912,
      "grad_norm": 2.282146692276001,
      "learning_rate": 2.7073469387755098e-05,
      "loss": 2.1633,
      "step": 22800
    },
    {
      "epoch": 0.916,
      "grad_norm": 2.229957103729248,
      "learning_rate": 2.5848979591836732e-05,
      "loss": 2.1476,
      "step": 22900
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.19563102722168,
      "learning_rate": 2.4624489795918362e-05,
      "loss": 2.1929,
      "step": 23000
    },
    {
      "epoch": 0.924,
      "grad_norm": 4.3057732582092285,
      "learning_rate": 2.34e-05,
      "loss": 2.164,
      "step": 23100
    },
    {
      "epoch": 0.928,
      "grad_norm": 2.768312931060791,
      "learning_rate": 2.2175510204081634e-05,
      "loss": 2.1456,
      "step": 23200
    },
    {
      "epoch": 0.932,
      "grad_norm": 4.137346267700195,
      "learning_rate": 2.0951020408163264e-05,
      "loss": 2.135,
      "step": 23300
    },
    {
      "epoch": 0.936,
      "grad_norm": 3.1485648155212402,
      "learning_rate": 1.9726530612244898e-05,
      "loss": 2.234,
      "step": 23400
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.087048530578613,
      "learning_rate": 1.850204081632653e-05,
      "loss": 2.1807,
      "step": 23500
    },
    {
      "epoch": 0.944,
      "grad_norm": 2.958287000656128,
      "learning_rate": 1.7277551020408162e-05,
      "loss": 2.2118,
      "step": 23600
    },
    {
      "epoch": 0.948,
      "grad_norm": 2.0536117553710938,
      "learning_rate": 1.6053061224489793e-05,
      "loss": 2.1564,
      "step": 23700
    },
    {
      "epoch": 0.952,
      "grad_norm": 2.6135904788970947,
      "learning_rate": 1.4828571428571427e-05,
      "loss": 2.2175,
      "step": 23800
    },
    {
      "epoch": 0.956,
      "grad_norm": 3.550633192062378,
      "learning_rate": 1.360408163265306e-05,
      "loss": 2.2363,
      "step": 23900
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.947993278503418,
      "learning_rate": 1.2379591836734691e-05,
      "loss": 2.2456,
      "step": 24000
    },
    {
      "epoch": 0.964,
      "grad_norm": 2.3953871726989746,
      "learning_rate": 1.1155102040816327e-05,
      "loss": 2.19,
      "step": 24100
    },
    {
      "epoch": 0.968,
      "grad_norm": 4.221810817718506,
      "learning_rate": 9.93061224489796e-06,
      "loss": 2.1904,
      "step": 24200
    },
    {
      "epoch": 0.972,
      "grad_norm": 6.616588115692139,
      "learning_rate": 8.706122448979592e-06,
      "loss": 2.1973,
      "step": 24300
    },
    {
      "epoch": 0.976,
      "grad_norm": 2.24784255027771,
      "learning_rate": 7.481632653061224e-06,
      "loss": 2.2411,
      "step": 24400
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1338655948638916,
      "learning_rate": 6.257142857142857e-06,
      "loss": 2.1796,
      "step": 24500
    },
    {
      "epoch": 0.984,
      "grad_norm": 4.293622970581055,
      "learning_rate": 5.03265306122449e-06,
      "loss": 2.1872,
      "step": 24600
    },
    {
      "epoch": 0.988,
      "grad_norm": 3.0300941467285156,
      "learning_rate": 3.808163265306122e-06,
      "loss": 2.1655,
      "step": 24700
    },
    {
      "epoch": 0.992,
      "grad_norm": 2.699725866317749,
      "learning_rate": 2.583673469387755e-06,
      "loss": 2.1668,
      "step": 24800
    },
    {
      "epoch": 0.996,
      "grad_norm": 3.2998123168945312,
      "learning_rate": 1.3591836734693878e-06,
      "loss": 2.1833,
      "step": 24900
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.2991080284118652,
      "learning_rate": 1.346938775510204e-07,
      "loss": 2.0934,
      "step": 25000
    }
  ],
  "logging_steps": 100,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3383545036800000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
