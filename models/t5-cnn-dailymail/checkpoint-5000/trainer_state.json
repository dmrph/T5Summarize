{
  "best_metric": 1.8519306182861328,
  "best_model_checkpoint": "models/t5-cnn-dailymail\\checkpoint-5000",
  "epoch": 1.0,
  "eval_steps": 2000,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 3.7190206050872803,
      "learning_rate": 5.82e-05,
      "loss": 3.5045,
      "step": 100
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.07709264755249,
      "learning_rate": 0.0001182,
      "loss": 2.615,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.144483804702759,
      "learning_rate": 0.00017819999999999997,
      "loss": 2.4392,
      "step": 300
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.292761325836182,
      "learning_rate": 0.0002382,
      "loss": 2.495,
      "step": 400
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.590158224105835,
      "learning_rate": 0.0002982,
      "loss": 2.4101,
      "step": 500
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.399181842803955,
      "learning_rate": 0.00029353333333333333,
      "loss": 2.3894,
      "step": 600
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.6081130504608154,
      "learning_rate": 0.00028686666666666663,
      "loss": 2.444,
      "step": 700
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.740793466567993,
      "learning_rate": 0.0002802,
      "loss": 2.3825,
      "step": 800
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.0000479221343994,
      "learning_rate": 0.00027353333333333333,
      "loss": 2.3768,
      "step": 900
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.167483329772949,
      "learning_rate": 0.00026686666666666663,
      "loss": 2.4249,
      "step": 1000
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.861419677734375,
      "learning_rate": 0.0002602,
      "loss": 2.4157,
      "step": 1100
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.407728910446167,
      "learning_rate": 0.00025353333333333333,
      "loss": 2.3649,
      "step": 1200
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.7941641807556152,
      "learning_rate": 0.00024686666666666663,
      "loss": 2.4192,
      "step": 1300
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.4308736324310303,
      "learning_rate": 0.00024019999999999996,
      "loss": 2.4922,
      "step": 1400
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.878624677658081,
      "learning_rate": 0.00023353333333333334,
      "loss": 2.3161,
      "step": 1500
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.2935614585876465,
      "learning_rate": 0.00022686666666666666,
      "loss": 2.3599,
      "step": 1600
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7430360317230225,
      "learning_rate": 0.00022019999999999999,
      "loss": 2.1966,
      "step": 1700
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.684183120727539,
      "learning_rate": 0.0002135333333333333,
      "loss": 2.4272,
      "step": 1800
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.4682226181030273,
      "learning_rate": 0.00020686666666666666,
      "loss": 2.3839,
      "step": 1900
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.799238443374634,
      "learning_rate": 0.0002002,
      "loss": 2.3976,
      "step": 2000
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.0276808738708496,
      "learning_rate": 0.0001935333333333333,
      "loss": 2.349,
      "step": 2100
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.1469664573669434,
      "learning_rate": 0.00018693333333333331,
      "loss": 2.4664,
      "step": 2200
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.6763410568237305,
      "learning_rate": 0.00018026666666666667,
      "loss": 2.447,
      "step": 2300
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.5149619579315186,
      "learning_rate": 0.0001736,
      "loss": 2.3462,
      "step": 2400
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.243152618408203,
      "learning_rate": 0.00016693333333333332,
      "loss": 2.3292,
      "step": 2500
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.328319549560547,
      "learning_rate": 0.00016026666666666667,
      "loss": 2.3033,
      "step": 2600
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.5891051292419434,
      "learning_rate": 0.0001536,
      "loss": 2.2777,
      "step": 2700
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.247620582580566,
      "learning_rate": 0.00014693333333333332,
      "loss": 2.3365,
      "step": 2800
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.5583837032318115,
      "learning_rate": 0.00014026666666666664,
      "loss": 2.3836,
      "step": 2900
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.869647741317749,
      "learning_rate": 0.0001336,
      "loss": 2.345,
      "step": 3000
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.387547254562378,
      "learning_rate": 0.00012693333333333332,
      "loss": 2.3203,
      "step": 3100
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.1674633026123047,
      "learning_rate": 0.00012026666666666666,
      "loss": 2.2718,
      "step": 3200
    },
    {
      "epoch": 0.66,
      "grad_norm": 5.327014923095703,
      "learning_rate": 0.00011359999999999998,
      "loss": 2.3182,
      "step": 3300
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.558265209197998,
      "learning_rate": 0.00010693333333333332,
      "loss": 2.2901,
      "step": 3400
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.2270567417144775,
      "learning_rate": 0.00010026666666666665,
      "loss": 2.3315,
      "step": 3500
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.944514751434326,
      "learning_rate": 9.36e-05,
      "loss": 2.2033,
      "step": 3600
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.283224582672119,
      "learning_rate": 8.693333333333334e-05,
      "loss": 2.3357,
      "step": 3700
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.88350772857666,
      "learning_rate": 8.026666666666666e-05,
      "loss": 2.2256,
      "step": 3800
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.8281750679016113,
      "learning_rate": 7.359999999999999e-05,
      "loss": 2.3162,
      "step": 3900
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.8312690258026123,
      "learning_rate": 6.693333333333332e-05,
      "loss": 2.2976,
      "step": 4000
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.66229510307312,
      "learning_rate": 6.026666666666666e-05,
      "loss": 2.2253,
      "step": 4100
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.1378939151763916,
      "learning_rate": 5.3599999999999995e-05,
      "loss": 2.3378,
      "step": 4200
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.34075665473938,
      "learning_rate": 4.693333333333333e-05,
      "loss": 2.4007,
      "step": 4300
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.6422083377838135,
      "learning_rate": 4.026666666666666e-05,
      "loss": 2.2695,
      "step": 4400
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.390942335128784,
      "learning_rate": 3.36e-05,
      "loss": 2.4198,
      "step": 4500
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.531914472579956,
      "learning_rate": 2.6999999999999996e-05,
      "loss": 2.2404,
      "step": 4600
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.649876117706299,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 2.3034,
      "step": 4700
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.6860249042510986,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 2.2702,
      "step": 4800
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.1784191131591797,
      "learning_rate": 7e-06,
      "loss": 2.343,
      "step": 4900
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.657991409301758,
      "learning_rate": 3.333333333333333e-07,
      "loss": 2.246,
      "step": 5000
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.8519306182861328,
      "eval_rouge1": 48.3317,
      "eval_rouge2": 22.1146,
      "eval_rougeL": 43.9219,
      "eval_rougeLsum": 43.9206,
      "eval_runtime": 13222.7815,
      "eval_samples_per_second": 0.076,
      "eval_steps_per_second": 0.038,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 676709007360000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
